{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ipfloater/ML_misc/blob/main/test_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGGTNre6uUQs",
    "outputId": "54ef6ffd-10ac-4876-a0ac-51dca737c7a2"
   },
   "outputs": [],
   "source": [
    "# run this only if you are running in Google Colab and pull the library from Github\n",
    "# !git clone https://github.com/ipfloater/ML_misc.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8bFtGCEpwgwA"
   },
   "outputs": [],
   "source": [
    "# run this only if you are running in Google Colab and pull the library from Github\\\n",
    "import sys\n",
    "\n",
    "sys.path = ['ML_misc/'] + sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test:\n",
    "* Pipeline\n",
    "* Ensemble estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_classifier_estimators_building (__main__.TestPipelineAndEnsemble) ... ok\n",
      "test_ensemble_classifier_run (__main__.TestPipelineAndEnsemble) ... INFO:sklearn_ML.ensemble_classifier:Logi fit timing: 0.0072\n",
      "INFO:sklearn_ML.ensemble_classifier:RandomForest fit timing: 0.2399\n",
      "INFO:sklearn_ML.ensemble_classifier:HistGradientBoosting fit timing: 0.2907\n",
      "INFO:sklearn_ML.ensemble_classifier:AdaBoosting fit timing: 0.2721\n",
      "INFO:sklearn_ML.ensemble_classifier:Bagging fit timing: 0.0760\n",
      "INFO:sklearn_ML.ensemble_classifier:StackingClassifier fit timing: 4.7486\n",
      "ok\n",
      "test_pipeline_building (__main__.TestPipelineAndEnsemble) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 5.760s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f3bdf720100>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from plotnine import ggplot, aes, geom_line, labs, theme_bw, scale_color_manual, ggtitle\n",
    "from sklearn_ML.ensemble_classifier import EnsembleClassifier\n",
    "from sklearn_ML.pipeline_utils import PipelineBuilder\n",
    "\n",
    "class TestPipelineAndEnsemble(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        # Create synthetic dataset\n",
    "        n_samples = 1000\n",
    "        X, y = make_classification(n_samples=n_samples, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
    "        weights = np.ones_like(y, dtype=float)\n",
    "        X_all = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "        nn = n_samples*80//100\n",
    "        X_train_w_cols = X_all.iloc[:nn]\n",
    "        y_train = pd.Series(y[:nn])\n",
    "        wt_train = pd.Series(weights[:nn])\n",
    "        X_test_w_cols = X_all.iloc[nn:]\n",
    "        y_test = pd.Series(y[nn:])\n",
    "        wt_test = pd.Series(weights[nn:])\n",
    "\n",
    "        self.model_data = (X_all, X_train_w_cols, y_train, wt_train, X_test_w_cols, y_test, wt_test)\n",
    "        self.excl_model_cols = []\n",
    "        self.bench_scores = []\n",
    "\n",
    "    def test_pipeline_building(self):\n",
    "        pipeline_lin, pipeline_nlin = PipelineBuilder.build_pipeline(self.model_data[0], self.excl_model_cols)\n",
    "        self.assertIsNotNone(pipeline_lin, \"Linear pipeline should not be None\")\n",
    "        self.assertIsNotNone(pipeline_nlin, \"Non-linear pipeline should not be None\")\n",
    "\n",
    "    def test_ensemble_classifier_run(self):\n",
    "        ensemble = EnsembleClassifier(self.model_data, self.excl_model_cols, self.bench_scores)\n",
    "        result = ensemble.run(include_stacking=True, perform_cv=False, list_of_estimators=['Logi', 'RandomForest', 'HistGradientBoosting', 'AdaBoosting', 'Bagging'])\n",
    "        self.assertIsInstance(result, pd.DataFrame, \"The result should be a DataFrame\")\n",
    "        self.assertFalse(result.empty, \"The result DataFrame should not be empty\")\n",
    "\n",
    "    def test_classifier_estimators_building(self):\n",
    "        pipeline_lin, pipeline_nlin = PipelineBuilder.build_pipeline(self.model_data[0], self.excl_model_cols)\n",
    "        ensemble = EnsembleClassifier(self.model_data, self.excl_model_cols, self.bench_scores)\n",
    "        estimators, stacking_clf = ensemble.build_classifier_estimators(pipeline_lin, pipeline_nlin)\n",
    "        self.assertTrue(len(estimators) > 0, \"There should be at least one estimator\")\n",
    "        self.assertIsNotNone(stacking_clf, \"Stacking classifier should not be None\")\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Tests:\n",
    "* PartialDependencyPlot\n",
    "* ROC_AUC curve\n",
    "* Precision_Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_partial_dependence_display (__main__.TestPipelineAndEnsemble) ... INFO:sklearn_ML.ensemble_classifier:Logi fit timing: 0.0077\n",
      "INFO:sklearn_ML.ensemble_classifier:RandomForest fit timing: 0.2323\n",
      "INFO:sklearn_ML.ensemble_classifier:HistGradientBoosting fit timing: 0.2740\n",
      "INFO:sklearn_ML.ensemble_classifier:AdaBoosting fit timing: 0.2689\n",
      "INFO:sklearn_ML.ensemble_classifier:Bagging fit timing: 0.0780\n",
      "INFO:sklearn_ML.ensemble_classifier:StackingClassifier fit timing: 5.1144\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from plotnine import ggplot, aes, geom_line, labs, theme_bw, scale_color_manual, ggtitle\n",
    "from sklearn_ML.ensemble_classifier import EnsembleClassifier\n",
    "from sklearn_ML.pipeline_utils import PipelineBuilder\n",
    "\n",
    "class TestPipelineAndEnsemble(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        # Create synthetic dataset\n",
    "        n_samples = 1000\n",
    "        X, y = make_classification(n_samples=n_samples, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
    "        weights = np.ones_like(y, dtype=float)\n",
    "        X_all = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "        nn = n_samples*80//100\n",
    "        X_train_w_cols = X_all.iloc[:nn]\n",
    "        y_train = pd.Series(y[:nn])\n",
    "        wt_train = pd.Series(weights[:nn])\n",
    "        X_test_w_cols = X_all.iloc[nn:]\n",
    "        y_test = pd.Series(y[nn:])\n",
    "        wt_test = pd.Series(weights[nn:])\n",
    "\n",
    "        self.model_data = (X_all, X_train_w_cols, y_train, wt_train, X_test_w_cols, y_test, wt_test)\n",
    "        self.excl_model_cols = []\n",
    "        self.bench_scores = []\n",
    "        # Run the ensemble classifier\n",
    "        self.ensemble = EnsembleClassifier(self.model_data, self.excl_model_cols, self.bench_scores)\n",
    "        self.result = self.ensemble.run(include_stacking=True, perform_cv=False, list_of_estimators=['Logi', 'RandomForest', 'HistGradientBoosting', 'AdaBoosting', 'Bagging'])\n",
    "\n",
    "    def test_roc_auc_and_precision_recall_curve(self):\n",
    "\n",
    "        # Filter results for test set predictions\n",
    "        test_results = self.result.query(f'type == \"test\"')\n",
    "\n",
    "        # Colors for plotting\n",
    "        colors = cycle(['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black'])\n",
    "\n",
    "        # Plot ROC AUC curve for each model using matplotlib\n",
    "        plt.figure()\n",
    "        for model_name in test_results['model'].unique():\n",
    "            model_results = test_results.query(f'model == \"{model_name}\"')\n",
    "            y_test = model_results['actual']\n",
    "            y_pred = model_results['pred']\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            color = next(colors)\n",
    "            plt.plot(fpr, tpr, color=color, lw=2, label=f'{model_name} (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve by Model')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot Precision-Recall curve for each model using matplotlib\n",
    "        plt.figure()\n",
    "        colors = cycle(['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black'])\n",
    "        for model_name in test_results['model'].unique():\n",
    "            model_results = test_results.query(f'model == \"{model_name}\"')\n",
    "            y_test = model_results['actual']\n",
    "            y_pred = model_results['pred']\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "            color = next(colors)\n",
    "            plt.plot(recall, precision, color=color, lw=2, label=f'{model_name}')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve by Model')\n",
    "        plt.legend(loc='lower left')\n",
    "        plt.show()\n",
    "\n",
    "    def test_roc_auc_and_precision_recall_curve_plotnine(self):\n",
    "        # Filter results for test set predictions\n",
    "        test_results = self.result.query(f'type == \"test\"')\n",
    "\n",
    "        # Prepare data for ROC AUC curve with plotnine\n",
    "        roc_data = []\n",
    "        for model_name in test_results['model'].unique():\n",
    "            model_results = test_results.query(f'model == \"{model_name}\"')\n",
    "            y_test = model_results['actual']\n",
    "            y_pred = model_results['pred']\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "            roc_data.append(pd.DataFrame({\n",
    "                'fpr': fpr,\n",
    "                'tpr': tpr,\n",
    "                'model': model_name\n",
    "            }))\n",
    "        roc_df = pd.concat(roc_data, axis=0)\n",
    "\n",
    "        # Plot ROC AUC curve using plotnine\n",
    "        roc_plot = (\n",
    "            ggplot(roc_df, aes(x='fpr', y='tpr', color='model')) +\n",
    "            geom_line() +\n",
    "            labs(x='False Positive Rate', y='True Positive Rate', title='Receiver Operating Characteristic (ROC) Curve by Model') +\n",
    "            theme_bw() +\n",
    "            scale_color_manual(values=['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black'])\n",
    "        )\n",
    "        print(roc_plot)\n",
    "\n",
    "        # Prepare data for Precision-Recall curve with plotnine\n",
    "        pr_data = []\n",
    "        for model_name in test_results['model'].unique():\n",
    "            model_results = test_results.query(f'model == \"{model_name}\"')\n",
    "            y_test = model_results['actual']\n",
    "            y_pred = model_results['pred']\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "            pr_data.append(pd.DataFrame({\n",
    "                'recall': recall,\n",
    "                'precision': precision,\n",
    "                'model': model_name\n",
    "            }))\n",
    "        pr_df = pd.concat(pr_data, axis=0)\n",
    "\n",
    "        # Plot Precision-Recall curve using plotnine\n",
    "        pr_plot = (\n",
    "            ggplot(pr_df, aes(x='recall', y='precision', color='model')) +\n",
    "            geom_line() +\n",
    "            labs(x='Recall', y='Precision', title='Precision-Recall Curve by Model') +\n",
    "            theme_bw() +\n",
    "            scale_color_manual(values=['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black'])\n",
    "        )\n",
    "        print(pr_plot)\n",
    "\n",
    "    def test_partial_dependence_display(self, model_name='RandomForest'):\n",
    "        estimators = self.ensemble.estimators\n",
    "\n",
    "        # Use the first estimator for partial dependence display\n",
    "        if estimators:\n",
    "            for mod_name, estimator in estimators:\n",
    "                if mod_name != model_name:\n",
    "                    continue\n",
    "                # features = [0, 1]\n",
    "                # Choosing top 5 features for partial dependence\n",
    "                if not hasattr(estimator[1], 'feature_importances_'):\n",
    "                    print(f'WARNING: feature_importances_ not available for {model_name}, skipping')\n",
    "                    break\n",
    "\n",
    "                features = np.argsort(estimator[1].feature_importances_)[-5:][::-1]\n",
    "                PartialDependenceDisplay.from_estimator(estimator, self.model_data[1], features)\n",
    "                plt.title(f'Partial Dependence Display for {mod_name}')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNoz5T9jklXi0Md12VRQXVm",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
